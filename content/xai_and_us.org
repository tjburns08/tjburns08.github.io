#+TITLE: Explainable AI and humanity
#+DATE: June 30 - June 30

[[./index.org][Home]]

** Explainable AI
Modern AI relies heavily on optimized [[https://en.wikipedia.org/wiki/Artificial_neural_network][artificial neural networks]] that these days do anything from generating [[https://www.gwern.net/GPT-3][creative fiction]] to producing [[https://en.wikipedia.org/wiki/DALL-E][images from a verbal description]]. A common criticism of these types of tools in [[https://en.wikipedia.org/wiki/Single-cell_analysis][my field]] is that they are "black boxes." We can see what they did but we can't see why. We biologists are used to having maximal clarity at every step. Part of our training is is being able to critique prior research, which becomes much harder to do if you just know that some AI tool with some acronym produced the answer.

So this is where the field of [[https://en.wikipedia.org/wiki/Explainable_artificial_intelligence][explainable artifical intelligence]] comes in. It's a rather broad pursuit of figuring out what these tools, which are otherwise not human-readable, are actually doing.

A lot of these explanations are highly visual. For example, a neural net that distinguishes healthy tissue from cancerous tissue in a medical image can be tweaked to show where on a given image the tool is focusing. When you're a physician who has to make life or death diagnostic decisions, you'd much rather know why a "helper AI" made the decision it did.

Another example is how I used [[./tjb_dimr_talk.pdf][visual tools]] to give my colleagues intuition around how dimension reduction algorithms perform on their single-cell data.

Explainable AI, or more broadly speaking, explainable black box algorithms, is a particularly broad field, and each new tool depends heavily on the algorithm itself and the context in which the algorithm is being used. But the concepts are similar, in that you're enabling the user to "get to know" the algorithm in order to be more effective with it and have a more comfortable relationship with it.

** Humanity at large
And that brings us to...us. Lets make the assumption for a moment that we are, or at least can be represented as, a set of evolutionarily optimized AI tools lumped together in what we call a brain. That means that that chunk of tissue we have behind our eyes is really a series of black box algorithms we're stuck with.

We spend a huge chunk of our lives getting to know ourselves and others...what these black boxes are all about. This ranges from determining as a kid whether you'd prefer to eat ice cream or ice berg lettuce on a hot summer day, to determining what you want in a lifetime partner.

But there's an abstract level above that. What songs send tingles down your spine? When was the last time you had a spiritual experinece? When you felt like you were part of something bigger? What artwork really stands out? Who is your favorite superhero and why?

Then there's a "production" layer. If you are given a paintbrush and you [[./just_paint.html][just paint]] something on the fly, what comes out? If you sit and write for an hour about whatever random thought crosses your mind, what comes out? What if you do the same, but it's only allowed to be poetry? 

And of course the social layer. What makes you like a person? Dislike a person? What caused that last angry outburst that you had that you didn't see coming?

Art, music, moving about the world and experiencing new things, having relationships, all of these are the explainable AI tools of the network of black boxes we call humanity. We have been on this since our emergence. We know what to do here.

So if you want some intuition around what these black box algorithms are doing, as the slowly work their way into our cars, computer, phones, watches, homes, and whatever else, we might want to look at how we get to know ourselves and our bretheren.

It probably won't be one tool that explains all of AI at that same time. It will probably be a number of tools and methods. It will probably be a constant struggle to get to know the machines as we try to get to know ourselves. The good news is if what I am saying carries any weight at all, then we are humans are already equipped to take on the task of explainable AI. We've been working on it for a long time. 




