#+Title: The Red Giant Problem
#+Author: Tyler Burns
#+Date: April 22, 2025

* Introduction
When I moved to Germany in 2017, I went to a handful of huge European cathedrals. They are as grandiose and elaborate as the pictures you've seen, but what I learned when I got here, was that many of these cathedrals took upwards of 100 years to build. Using pre-industrial revolution technology. In a time when the average life span was maybe 50 or 60 years if you survived childhood. If we assume a generation is around 30 years, then this means that if you spent your life building the cathedral, your great grandkids might be able to use it after you're long gone.

In short, to build a cathedral, you had to think in time scales beyond your life. Perhaps those building a cathedral got a boost from religion. But the point I want to make is, we don't really have that kind of long term thinking these days. I'm not the first person to bring this up. I would say that we are sort of stuck in a system that incentivizes short term rewards. So there is an obvious question here of what could we build if we collectively had the long term mindset that the cathedral builders had hundreds of years ago?

There has indeed been some work to this end, and there is a movement called [[https://en.wikipedia.org/wiki/Longtermism][Longtermism]] that is trying to get people to think in these longer time scales. This was also catalyzed by a book called [[https://en.wikipedia.org/wiki/Anathem][Anathem]] by Neil Stephenson. So then this begs the question: what is the longest time horizon we can operate in?

Well if we zoom out to around 5 billion years from now, the Sun becomes a red giant, boils the oceans and destroys the biosphere. Plenty of people talk about the end times, whether it is based in religious doctrine, nuclear war, AI takeover, asteroids, and so forth. But even if we make it past all of that, physics tells us that the Sun will exhaust the hydrogen in its core and enter the red giant phase. So, in cosmic time scales, we are objectively toast.

I call this the red giant problem. The purpose of this essay is to argue that if we put this problem front and center and ask what to do about it, it actually gives our civilization a helpful framework whereby we can solve the problems that we are currently facing at the moment. Long term thinking to the rescue.
* What to do about the problem
Let's look at how we solve the red giant problem. The first thing is that have to solve long-range space travel. This is something Elon Musk has talked about, and part of his motivation to found SpaceX (and yes he's not super popular right now, but we can at least think in terms of pre-politics Elon Musk and assume his brain got a software update that a lot of people don't like). So this means we have to work on space travel.

One thing that definitely helps with all things space travel is solving for nuclear fusion. Fusion apparently solves many problems. It opens up possibilities for faster and longer space travel, and better energy storage to this end. Which of course implies things like colonies on Mars, and asteroid mining. But also, it solves a lot of the climate change issues overnight. Because we don't have to burn [[https://www.youtube.com/shorts/99W2Ll4GXNo][coal]] anymore, or deal with the risks involved in fission power. And you get a lot more energy than you'd otherwise get with wind, hydroelectric, and geothermal. So that's nice, I would say. We should probably invest a bit in this one.

And of course, fusion would help with the insane energy demands that are going to hit us as we transition to an AI-centric civilization. Even if AI stops progressing tomorrow, forever, we still have yet to fully realize the full potential of what AI is today. Now there are huge existential issues around AI that I think should be taken very seriously. I am not going to discount any of that. I'm only going to say that if the cat is really out of the bag, and we are stuck with AI, like it or not, then we should probably at least turn it loose on the bigger problems. Like that of fusion. Like those of space travel.

And this brings us to what I am using AI to work on: cancer. Cancer has been my north star for a very long time. It is a very hard problem, and it could be that the "cure" for cancer might differ, cancer by cancer. But either way, people have been saying since I was in grad school, that the cure for cancer, if it exists, will require us to be in a different scientific paradigm than the one we are currently in. At the time, there was hope that "systems biology" would change the game. Then it was CAR-T cells. And now, it's agentic AI.

The problem of cancer turns out to be connected to a bunch of other problems. Like that of prevention, which brings us to the problem of humanity dumping all kinds of garbage and chemical pollution into the environment. So it would be nice if we could figure out how to stop that. Then we have the problem of human suffering in general. A lot of cancer can be treated, in comparison to 200 years ago. However, no one wants to suffer however many rounds of chemotherapy and radiotherapy. So there is a whole set of problems there around mitigating suffering if you are sick with something that is hard to cure. Or if you are simply very old and everything hurts. And of course, if humanity has no choice but to travel in space to habitable planets elsewhere, or live in space stations and such, there is going to be a lot of cancer due to increased radiation exposure. So we really do have to work on this cancer problem.

Then we have the class of problems that involve us blowing oursleves up long before the Sun becomes a red giant. First off, I would like to at least guess that if humanity is indeed long gone, that perhaps the dolphins have become intelligent or something like that. Even if not, there is still going to be a biosphere that is going to suffer when the Sun changes. So we have to keep them in mind too.

But back to blowing oursleves up. We should probably work on issues related to the failure modes that lead to war, pestilence, famine, and death. The age-old question of how can we all just get along? How can we stop misaligned incentives in their tracks? How can we make things fair, and what does that actually mean? In other words, there are a bunch of problems around ethics that need to be worked on right now. Along with doing things like diagnosing what causes a society to collapse in the first place. There has indeed been some [[https://risk.princeton.edu/img/Historical_Collapse_Resources/Tainter_The_Collapse_of_Complex_Societies_ch_1_2_5_6.pdf][work]] on that. But I'd say given that we're all globally interconnected, a collapse that happens in one place could very well destabilize the rest of the world. So no major collapses, please.

Related to ethics, there is the problem of how we should live, and what does a good life mean? If we want to become the society that is about to relocate an entire biosphere, we probably need to optimize for wisdom. There are people like [[https://vervaekefoundation.org/][John Vervaeke]] who is specializing in this exactly, and I think more resources should be allocated to people like him. Just as martial arts evolved into MMA, I think we have yet to see a "MMA moment" for the major religions and wisdom traditions on the planet. I'm guessing that each one has something to give. What happens when you rigorously take the best from all of them? What does that look like?
* Conclusions
Here, we introduced the red giant problem. We framed it as a way to get humanity to think long term again. We state that it is absolutely true that humanity and the biosphere will end when the sun becomes a red giant in 5 billion years. So we have between now and then to relocate the entire biosphere. And yes, one might say that we have plenty of time. But if there is anything that I learned in school, it's that humanity is going to wait until the night before to do anything about it. So we have to at least start brainstorming now.

But what is interesting that the red giant problem is that every problem we found that is associated with relocating the biosphere is being worked on today by someone. So what this effectively does is takes the big problems that humanity is facing right now and puts it together into a nice framework where we can see the whole picture and how they are related.

We have to cure cancer because of cosmic rays in space. We have to solve for space travel because we will be spending a bit of time doing that. We have to solve for fusion because that makes a lot of this much much easier, and it solves a lot of the existential issues that came about from burning fossil fuels. We have to solve for world peace so we don't blow each other up with fusion bombs between now and 5 billion years for now. At the individual level, we have to solve for wisdom so we can take all this in, act on reason, and understand how to properly use our emotions.

And of course, if we are stuck with AI from here on out, then we might as well figure out how to use it to work on these problems with us. This is a whole can of worms, but we should at least have the intent to get it working on the problems we have been unable to solve up until now.

In short, we are already working on a lot of the problems that will allow us to relocate the biosphere in 5 billion years. However, the red giant problem gives us a way to unify these problems and orient toward something that is definite and inevitable. Earth's final problem. So when you're going about your day, you can ask yourself "how might this move us toward a solution to the red giant problem. What modificaions might orient us more in that direction?" See what answers materialize.
* AI feedback editing
** first pass
#+begin_src sh :results output
source ~/.zshrc
text=$(sed -n 1,41p red_giant_problem.org)
chatbot "o4mh" "Please provide feedback for this writing, in terms of merit. How would you solve this problem? What am I missing? What can I double down on? Text is here: $text"
#+end_src

#+RESULTS:
#+begin_example
Here’s some structured feedback on “The Red Giant Problem,” along with some ideas for how you might sharpen it, fill the gaps, and double‑down where it really pays off.

1. Merits
 • Compelling hook.  The cathedral analogy is vivid and immediately grounds “deep time” in a human story.
 • Big‑picture clarity.  You lay out a single unambiguous deadline—“Sun goes red giant in 5 Gyr”—and you use it to unify a lot of otherwise disparate issues.
 • Interdisciplinary sweep.  Technology (fusion, space‑travel), ethics (war, suffering), culture (wisdom traditions), AI, environment, even non‑human life all appear under one umbrella.

2. Where to tighten
 a. Focus your thesis.  Right now your intro wanders: short‑termism → longtermism → Stephenson’s Anathem → red giant.  Say in one crisp sentence, “I propose ‘the red giant problem’ as the ultimate long‑term frame: if we must relocate Earth’s biosphere by Sun’s death, what coherent plan emerges for technology, society, ethics, and culture?”
 b. Clear roadmap.  After that thesis sentence, bullet the main pillars you’ll cover (e.g. propulsion & energy, biosphere‑preservation, governance, wisdom & culture).
 c. Transitions & signposting.  Your space‑travel paragraph jumps to fusion, then to climate change, then to AI.  Break into sub‑headings: “2.1 Energy & Fusion,” “2.2 Propulsion & In‑space Infrastructure,” “2.3 AI as a Research Multiplier,” etc.

3. Missing elements
 a. Gigascale astrophysical engineering.  If the sun’s steady growth in luminosity is the true killer, one option is “star‑lifting” (removing mass from the Sun to extend its main sequence life) or using a Dyson swarm as a sun‑shade.  You mention “relocate the biosphere,” but you could also mention “modify the star or orbit of the planet.”
 b. Discount‑rate and institutional reform.  What concrete lever will push society from annual profit‑cycles to millennia‑scale planning?  Ideas to consider:
   – Constitutional or legal rights for future generations (a “Guardian for the Future”).
   – Global long‑duration trust funds, carbon dividends extended to a “biosphere‑relocation fund.”
   – Integrated Assessment Models expanded to a 5 Gyr horizon.
 c. Biosphere archiving vs. migration.  You assume full biological transport—what about high‑fidelity digital backups of genomes, seed banks, even whole‑ecosystem “snapshots”?  That may lower the bar.
 d. Culture, values & memory.  You gesture at “wisdom” but could flesh out how to transmit moral frameworks across thousands of years.  (Ceremonies, myth, digital preserve + ritual renewal, maybe an evolving “library of future advice” seeded by diverse cultures.)
 e. Roadmap for existential‑risk reduction.  You mention nuclear, AI, war—but can you give an explicit “top five” map of existential threats with countermeasures, so that readers see short‑term payoffs en route to the red‑giant goal?

4. Where to double‑down
 a. Fusion + AI synergy.  You hint that AI could accelerate fusion R&D.  That’s a concrete, fundable, sub‑project: write a mini‑white‑paper on using deep‑RL for plasma stabilization or high‑throughput materials search for reactor walls.  That makes your narrative action‑oriented.
 b. Wisdom traditions “MMA moment.”  That’s a colorful, original image—expand it.  Sketch one or two prototype “metareligious” curricula or retreats that synthesize Buddhism, Stoicism, indigenous wisdom, and cognitive science under one roof.  Even propose a name for it.
 c. Bio‑preservation testbeds.  Cite current work on seed vaults, cryopreservation, microbial culture banks, and propose an explicit “Plan Beta” for Earth‑offload to the Moon or L2.  A detailed staging plan (Earth → lunar hothouse → orbital ark) would show how you really mean business.
 d. Governance prototypes.  You call for world peace, but can you point to candidate institutions (e.g. UN‑style bodies with 1,000‑year charters, tech platforms for participatory foresight) and sketch how they’d be funded, staffed, chartered?

5. Sample revised outline
 I. Introduction
   1. Cathedral story → short‑termism
   2. Thesis: the red‑giant problem as unifying long‑term frame
   3. Roadmap of pillars
 II. Energy & Propulsion
   1. Fusion + AI acceleration
   2. Star‑shade, star‑lifting, orbital mechanics
 III. Biosphere Preservation
   1. Digital & genetic archives
   2. Lunar/orbital testbeds
   3. Interstellar ark concepts
 IV. Existential‑Risk & Governance
   1. War, AI alignment, pandemics
   2. Legal rights of future gens
   3. Global “Office for the Future”
 V. Wisdom & Culture
   1. MMA moment in religion/philosophy
   2. Long‑term education & narrative
   3. Tools for deep‑time empathy
 VI. Conclusion & Call to Action
   – “Every project you fund or join: ask, does it inch us
#+end_example
