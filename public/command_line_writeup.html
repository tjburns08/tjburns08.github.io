<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>How I made a command line chatbot</title>
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="simple.css" />
<style>
  .dark-mode {
    --bg: #212121;
    --accent-bg: #2b2b2b;
    --text: #dcdcdc;
    --text-light: #ababab;
    --accent: #ffb300;
    /*--code: #f06292;*/
    --preformatted: #ccc;
    --disabled: #111;
  }
  .dark-mode img,
  .dark-mode video {
    opacity: 0.8;
  }
  .toggle-theme-btn {
      transform: scale(0.7);
      opacity: 0.4;
      transition: opacity 0.2s;
    }
    .toggle-theme-btn:hover {
      opacity: 0.4;
    }
</style>
<script>
 function toggleDarkMode() {
    const body = document.body;
    body.classList.toggle("dark-mode");
    // Save the user's theme preference to localStorage
    if (body.classList.contains("dark-mode")) {
      localStorage.setItem("theme", "dark");
    } else {
      localStorage.setItem("theme", "light");
    }
  }

  function setDefaultDarkMode() {
    // Retrieve the user's theme preference from localStorage
    const storedTheme = localStorage.getItem("theme");

    // If the stored theme is light, do nothing; otherwise, set it to dark
    if (storedTheme !== "light") {
      document.body.classList.add("dark-mode");
    }
  }

  // Set the default mode to dark when the DOM is fully loaded
  document.addEventListener('DOMContentLoaded', setDefaultDarkMode);
</script>
</head>
<body>
<div id="preamble" class="status">
<div style="position: fixed; top: 10px; right: 10px;">
         <button class="toggle-theme-btn" onclick="toggleDarkMode()">Light/Dark</button>
       </div>
</div>
<div id="content" class="content">
<h1 class="title">How I made a command line chatbot</h1>
<p>
<a href="./index.html">Home</a>
</p>

<hr />
<p>
<i>I went to the woods because I wished to live deliberately, to front only the essential facts of life, and see if I could not learn what it had to teach, and not, when I came to die, discover that I had not lived.</i>
</p>

<p>
Henry David Thoreau, <i>Walden</i>
</p>
<hr />

<div id="outline-container-org4ed4b79" class="outline-2">
<h2 id="org4ed4b79">Introduction</h2>
<div class="outline-text-2" id="text-org4ed4b79">
<p>
Since the end of 2022, we have been inundated with LLM chatbots in our everyday lives. The typical use involves some sort of interface that we sign into, where our previous chats can be saved, and so forth. At some point early on, these chatbots were available via API. Here, I want to show how I made a chatbot that can be called from the command line anywhere on my computer.
</p>

<p>
The use case I'll show you is that of the literate programming environment, which in turn allows you to basically have and store platonic dialogues that are in turn saved and stored. This helps me with specific use cases, like getting feedback on journal entries and notes in real time. A specific example of this involves my German learning, where I often use LLMs to be a conversational partner that provides feedback in real time. Otherwise, in my line of work, I do a lot of research, so I often use LLMs to bounce ideas off of, and so forth. A literate programming environment helps save this feedback directly into the notes I'm taking.
</p>

<p>
In short, having LLMs available on the command line is useful, and here, I'm going to show you how I do it. The punchline is that it is not particularly hard to do.
</p>
</div>
</div>
<div id="outline-container-orgb0a7485" class="outline-2">
<h2 id="orgb0a7485">The command line interface</h2>
<div class="outline-text-2" id="text-orgb0a7485">
<p>
The first thing we have to do is make a python script where we call an API. At the time of writing <span class="timestamp-wrapper"><span class="timestamp">[2025-01-27 Mon]</span></span>, Deepseek R1 has just come out, which provides chain-of-thought reasoning (currently state of the art), the likes of GPT-o1 (currently state of the art), but for far cheaper in terms of API calls. Not to mention its open source, so it might be down the line if I get enough computational muscle, I can run it locally.
</p>

<p>
In terms of calling the API, there are plenty of options, but I use <a href="https://openrouter.ai/">OpenRouter</a>. This gives me access to the GPT models, Claude, Deepseek, and a host of other models. You can browse available models <a href="https://openrouter.ai/models">here</a>. When you sign up, you will get an API key, and the ability to buy credits. To give you an idea of how cheap it is, I put down $5 three days ago (date of this sentence: <span class="timestamp-wrapper"><span class="timestamp">[2025-01-27 Mon]</span></span>), and after extensive use primarily of Claude, I have $4.74 remaining.
</p>

<p>
I wrote a python script called chatbot.py, that takes in as input the desired model to use (currently GPT-4o, Claude, Deepseek R1) and the prompt. It turn prints the answer. The script is as follows:
</p>

<div class="org-src-container">
<pre class="src src-python"><span class="org-comment-delimiter">#</span><span class="org-comment">!/usr/bin/env python3</span>
<span class="org-keyword">from</span> openai <span class="org-keyword">import</span> OpenAI
<span class="org-keyword">import</span> sys

<span class="org-variable-name">ds</span> = <span class="org-string">"deepseek/deepseek-r1"</span>
<span class="org-variable-name">gpt3</span> = <span class="org-string">"openai/gpt-3.5-turbo"</span>
<span class="org-variable-name">gpt4</span> = <span class="org-string">"openai/gpt-4o-2024-11-20"</span>
<span class="org-variable-name">claude</span> = <span class="org-string">"anthropic/claude-3.5-sonnet-20240620"</span>

<span class="org-comment-delimiter"># </span><span class="org-comment">Ensure the question is passed as a command-line argument</span>
<span class="org-keyword">if</span> <span class="org-builtin">len</span>(sys.argv) &lt; 3:
    <span class="org-builtin">print</span>(<span class="org-string">"Usage: python chatbot.py &lt;model&gt; \"&lt;your question&gt;\""</span>)
    <span class="org-builtin">print</span>(<span class="org-string">"Model options: gpt or deepseek"</span>)
    sys.<span class="org-constant">exit</span>(1)

<span class="org-comment-delimiter"># </span><span class="org-comment">Get the question from the command-line argument</span>
<span class="org-variable-name">model_choice</span> = sys.argv[1].lower()
<span class="org-variable-name">user_question</span> = sys.argv[2]

<span class="org-comment-delimiter"># </span><span class="org-comment">Map the user's model choice to the appropriate model</span>
<span class="org-keyword">if</span> model_choice == <span class="org-string">"gpt3"</span>:
    model = gpt3
<span class="org-keyword">elif</span> model_choice == <span class="org-string">"gpt4"</span>:
    model = gpt4
<span class="org-keyword">elif</span> model_choice == <span class="org-string">"deepseek"</span>:
    model = ds
<span class="org-keyword">elif</span> model_choice == <span class="org-string">"claude"</span>:
    model = claude
<span class="org-keyword">else</span>:
    <span class="org-builtin">print</span>(<span class="org-string">"Invalid model choice. Please choose either 'gpt' or 'deepseek'."</span>)
    sys.<span class="org-constant">exit</span>(1)


client = OpenAI(
  base_url=<span class="org-string">"https://openrouter.ai/api/v1"</span>,
  api_key=<span class="org-string">"YOUR_API_KEY_HERE"</span>,
)

completion = client.chat.completions.create(
  model=model,
  messages=[
    {
      <span class="org-string">"role"</span>: <span class="org-string">"user"</span>,
      <span class="org-string">"content"</span>: user_question
    }
  ]
)
<span class="org-builtin">print</span>(completion.choices[0].message.content)
</pre>
</div>

<p>
This is the first step. You can then run this by going to the directly that this script is in and running:
</p>

<div class="org-src-container">
<pre class="src src-sh">python chatbot.py <span class="org-string">"your model here"</span> <span class="org-string">"your prompt here"</span>
</pre>
</div>

<p>
For example:
</p>

<div class="org-src-container">
<pre class="src src-sh">python chatbot.py <span class="org-string">"gpt3"</span> <span class="org-string">"What is 5 + 2?"</span>
</pre>
</div>

<pre class="example">
5 + 2 = 7
</pre>


<p>
Great. Now the next step is to make this script available anywhere on your computer. The way you do that is to add this script to your PATH. First, I made a directory called scripts that is directly in my PATH.
</p>

<div class="org-src-container">
<pre class="src src-sh">mkdir -p ~/scripts
</pre>
</div>

<p>
Next, I moved the chatbot python script into that new directory:
</p>

<div class="org-src-container">
<pre class="src src-sh">mv chatbot.py ~/scripts/chatbot
chmod +x ~/scripts/chatbot <span class="org-comment-delimiter"># </span><span class="org-comment">permissions</span>
</pre>
</div>

<p>
Then I place this directory into my PATH, which for me is in ~/.zshrc
</p>

<div class="org-src-container">
<pre class="src src-sh"><span class="org-builtin">export</span> <span class="org-variable-name">PATH</span>=<span class="org-string">"$HOME/scripts:$PATH"</span>
</pre>
</div>

<p>
Then, I applied the changes with:
</p>

<div class="org-src-container">
<pre class="src src-sh"><span class="org-builtin">source</span> ~/.zshrc
</pre>
</div>

<p>
And from there, I can call chatbot globally by using:
</p>

<div class="org-src-container">
<pre class="src src-sh">chatbot <span class="org-string">"gpt3"</span> <span class="org-string">"What is 5 + 2?"</span>
</pre>
</div>

<pre class="example">
5 + 2 = 7
</pre>


<p>
In terms of using it on the command line, that is all there is to it. But if you note in the example above, this script ran directly in this writeup, because I am writing this article in a literate programming environment. This one of my preferred ways of using LLMs, as a conversational partner in real time.
</p>

<p>
Thus, the next section will show you how to get this running in a literate programming environment.
</p>
</div>
</div>

<div id="outline-container-orgdc0918e" class="outline-2">
<h2 id="orgdc0918e">The literate programming environment</h2>
<div class="outline-text-2" id="text-orgdc0918e">
</div>
<div id="outline-container-org343a1de" class="outline-3">
<h3 id="org343a1de">R Markdown and Jupyter Notebooks</h3>
<div class="outline-text-3" id="text-org343a1de">
<p>
The spoiler alert upfront is that in order to use the new script in a literate programming environment, you just have to get it to execute shell scripts. In R Markdown, there is an option to run bash. Jupyter notebooks have <a href="https://github.com/dahn-zk/zsh-jupyter-kernel">options</a> as well. One of the key things that I've had to do to get the literate programming environment to recognize the script, is in every code block where I run it, I have to source my zshrc file. Like this:
</p>

<div class="org-src-container">
<pre class="src src-sh"><span class="org-builtin">source</span> ~/.zshrc
chatbot <span class="org-string">"gpt3"</span> <span class="org-string">"What is 5 + 2?"</span>
</pre>
</div>

<pre class="example">
5 + 2 equals 7.
</pre>


<p>
Maybe you won't have this problem, but if you do, that is how you get around it.
</p>
</div>
</div>
<div id="outline-container-orgd10ffb8" class="outline-3">
<h3 id="orgd10ffb8">Emacs Org-Mode</h3>
<div class="outline-text-3" id="text-orgd10ffb8">
<p>
Now this section is for Emacs users who use org mode. This is the literate programming environment that I prefer, and I am writing this article directly in it. I am specifically using <a href="https://orgmode.org/worg/org-contrib/babel/">Babel</a> which allows for active code use in Org. This comes with Doom Emacs (I'm currently using this) and Spacemacs (I started with this).
</p>

<p>
The way you start a shell block here is by doing "<code>#+begin_src sh :results output</code>" and then another line underneath the code "<code>#+end_src</code>." There is a keybinding that shortcuts this. Just go to a new line and type "&lt;s + Tab." You'll see why this is important in a minute.
</p>

<p>
So go ahead and test this out on your computer and then we'll move to the next bit, where we make a keybinding specific to the making and use of our chatbot script.
</p>

<p>
Now what I have set up is a keybinding that sets up specifically this:
</p>

<p>
<code>#+begin_src sh :results output</code><br />
source ~/.zshrc<br />
chatbot "claude" "test"<br />
</p>

<p>
<code>#+end_src</code>
</p>

<p>
I can get the above block by typing "&lt;chat + Tab" anywhere I'd otherwise insert a code block within an Org file.
</p>

<p>
Anyway the way you set up this keyboard shortcut, at least in Doom emacs, is by going into your config file (config.el) within your .doom.d directory, going into your "after 'org" block, and adding the following lines.
</p>

<div class="org-src-container">
<pre class="src src-elisp">(<span class="org-keyword">require</span> '<span class="org-constant">org-tempo</span>)
(add-to-list 'org-structure-template-alist
        '(<span class="org-string">"chat"</span> . <span class="org-string">"src sh :results output\nsource ~/.zshrc\nchatbot \"claude\" \"test\""</span>))
</pre>
</div>

<p>
You'll see that there is an unnecessary line that sits between the chatbot call and <code>end_src</code>. I have not yet figured out how to remove that line, but the text cursor automatically sits at that line, so you just have to press delete right after the block has been made and the line goes away. So really just think of it as "&lt;chat + Tab + Delete."
</p>
</div>
</div>
</div>
<div id="outline-container-orgfd56f84" class="outline-2">
<h2 id="orgfd56f84">Discussion</h2>
<div class="outline-text-2" id="text-orgfd56f84">
<p>
Since I made this command line cool and figured how to use it in a literate programming context, it has increased my productivity especially in the contexts of my German learning (I am American living in Berlin), and my research work. The more general theme is that I write prolifically in my literate programming environment (Org-Mode), and now I can get direct feedback from LLMs directly within this environment.
</p>

<p>
In general, I <a href="https://www.paulgraham.com/words.html">write to think</a>. Thus, now I can think and get real time feedback on my thoughts by LLMs that are becoming increasingly better, and are hallucinating less often. I have seen the occasional comment about how LLMs are going to reduce our ability to think about stuff, because we will end up <a href="https://hackernoon.com/the-stanford-grad-who-forgot-how-to-think">outsourcing our cognition</a> to them. My general goal is to use LLMs as a way to help me think more effectively about stuff, because being good a thinking about stuff is a core value of mine.
</p>

<p>
This is similar to bench pressing by myself versus with a spotter. As opposed to getting a spotter to do the bench pressing for me while I sit back and watch. That is a sort of litmus test for my LLM use: does it increase brain activity or <a href="https://paulgraham.com/writes.html">decrease it</a>? If my brain activity goes up or at least stays the same, then I will consider it a valid use case for me. If my brain activity goes down, then that is not a valid use case for me.
</p>

<p>
Future directions with this script involve figuring out how to get this to search the internet, which is what Bing Chat (aka <a href="https://www.lesswrong.com/posts/jtoPawEhLNXNxvgTT/bing-chat-is-blatantly-aggressively-misaligned">Sydney</a>) originally did, and other tools like GPT-4o and perplexity do now. I know that this might seem a bit like reinventing the wheel, but one of the things that I want to do is understand how these things work under the hood. And one way to understand how something works is to <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">build it yourself</a>.
</p>

<p>
In short, having a LLM in a literate programming environment has done me some good, and I hope it will do some of you some good too. Give this a shot if only for the exercise of knowing how to do it. It's nice to be independent of the interfaces, and it's a "gateway drug" into building your own apps.
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: January 24, 2025 - January 27, 2025</p>
<p class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 28.1 (<a href="https://orgmode.org">Org</a> mode 9.5.2)</p>
</div>
</body>
</html>
